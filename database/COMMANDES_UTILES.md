# ğŸ”§ Commandes Utiles - Gestion des Entreprises

## ğŸ“Š VÃ©rifier les Statistiques

```bash
cd database

# Statistiques complÃ¨tes
python3 -c "
import json

with open('jobs_data.json', 'r') as f:
    jobs = json.load(f)
    print(f'ğŸ“Š jobs_data.json: {jobs[\"total_companies\"]} entreprises')

with open('company_news.json', 'r') as f:
    news = json.load(f)
    total_news = sum(len(company.get('news_items', [])) for company in news.values())
    successful = sum(1 for company in news.values() if company.get('scrape_metadata', {}).get('success'))
    print(f'ğŸ“° company_news.json: {len(news)} entreprises')
    print(f'   âœ… SuccÃ¨s: {successful}')
    print(f'   ğŸ“° Total actualitÃ©s: {total_news}')
    print(f'   ğŸ“ˆ Moyenne: {total_news/len(news):.1f} actualitÃ©s/entreprise')
"
```

## ğŸ” Rechercher une Entreprise SpÃ©cifique

```bash
cd database

# Voir les actualitÃ©s d'une entreprise
python3 -c "
import json
import sys

company_name = 'Pottery Barn'  # Changer le nom ici

with open('company_news.json', 'r') as f:
    news = json.load(f)
    
if company_name in news:
    company = news[company_name]
    print(f'ğŸ¢ {company_name}')
    print(f'   Score Presti: {company.get(\"overall_assessment\", {}).get(\"presti_fit_score\")}/10')
    print(f'   ActualitÃ©s: {len(company.get(\"news_items\", []))}')
    print()
    for item in company.get('news_items', []):
        print(f'   â€¢ {item[\"title\"]} ({item[\"relevance_score\"]}/10)')
else:
    print(f'âŒ {company_name} non trouvÃ©')
"
```

## ğŸ“¥ Mettre Ã  Jour les ActualitÃ©s (avec API OpenAI)

```bash
cd database

# Activer l'environnement virtuel
source venv_async/bin/activate

# Option 1: Tester une seule entreprise
OPENAI_API_KEY=your_key python3 scrape_company_news_async.py test "Company Name"

# Option 2: Scraper toutes les entreprises
OPENAI_API_KEY=your_key python3 scrape_company_news_async.py

# DÃ©ployer vers le frontend
cp company_news.json ../public/news_data.json
```

## â• Ajouter de Nouvelles Entreprises

### MÃ©thode 1: Sans API (donnÃ©es manuelles)

```bash
cd database

# 1. Modifier generate_new_companies_data.py
# Ajouter les entreprises dans NEW_COMPANIES_DATA

# 2. ExÃ©cuter
python3 generate_new_companies_data.py

# 3. Mettre Ã  jour jobs_data.json manuellement ou crÃ©er un script

# 4. DÃ©ployer vers le frontend
cp company_news.json ../public/news_data.json
```

### MÃ©thode 2: Avec API OpenAI (recommandÃ©)

```bash
cd database

# 1. Ajouter entreprises Ã  jobs_data.json
# CrÃ©er un script add_companies.py:
cat > add_companies.py << 'EOF'
import json

with open('jobs_data.json', 'r') as f:
    data = json.load(f)

new_companies = [
    {
        "success": True,
        "jobs": [],
        "nb_jobs": 0,
        "company": {
            "name": "New Company",
            "website": "https://...",
            "industry": "Furniture",
            "employees": "500-1000"
        }
    }
]

data['companies'].extend(new_companies)
data['total_companies'] = len(data['companies'])

with open('jobs_data.json', 'w') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

print(f"âœ… {len(new_companies)} entreprises ajoutÃ©es")
EOF

python3 add_companies.py

# 2. Scraper les actualitÃ©s
source venv_async/bin/activate
OPENAI_API_KEY=your_key python3 scrape_company_news_async.py

# 3. DÃ©ployer
cp company_news.json ../public/news_data.json
```

## ğŸ”„ Workflow Complet de Mise Ã  Jour

```bash
cd database

# 1. Activer l'environnement
source venv_async/bin/activate

# 2. Mettre Ã  jour les actualitÃ©s
OPENAI_API_KEY=your_key python3 scrape_company_news_async.py

# 3. DÃ©ployer vers le frontend
cp company_news.json ../public/news_data.json

# 4. VÃ©rifier
python3 -c "
import json
with open('../public/news_data.json', 'r') as f:
    data = json.load(f)
    print(f'âœ… {len(data)} entreprises disponibles dans le frontend')
"

# 5. RedÃ©marrer l'app (si nÃ©cessaire)
# L'app Next.js dÃ©tecte automatiquement les changements
```

## ğŸ“¤ Exporter les DonnÃ©es

```bash
cd database

# Export CSV des scores Presti
python3 -c "
import json
import csv

with open('company_news.json', 'r') as f:
    news = json.load(f)

with open('presti_scores.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['Entreprise', 'Score Presti', 'Nb ActualitÃ©s', 'OpportunitÃ©s'])
    
    for company_name, data in sorted(news.items()):
        score = data.get('overall_assessment', {}).get('presti_fit_score', 0)
        nb_news = len(data.get('news_items', []))
        opps = '; '.join(data.get('overall_assessment', {}).get('key_opportunities', []))
        writer.writerow([company_name, score, nb_news, opps])

print('âœ… Export crÃ©Ã©: presti_scores.csv')
"
```

## ğŸ” Filtrer par Score

```bash
cd database

# Entreprises avec score >= 8
python3 -c "
import json

with open('company_news.json', 'r') as f:
    news = json.load(f)

high_scores = {
    name: data for name, data in news.items()
    if data.get('overall_assessment', {}).get('presti_fit_score', 0) >= 8
}

print(f'ğŸ¯ {len(high_scores)} entreprises avec score >= 8:')
for name, data in sorted(high_scores.items(), 
                         key=lambda x: x[1].get('overall_assessment', {}).get('presti_fit_score', 0),
                         reverse=True):
    score = data.get('overall_assessment', {}).get('presti_fit_score')
    print(f'   {score}/10 - {name}')
"
```

## ğŸ§¹ Nettoyage

```bash
cd database

# Supprimer les fichiers temporaires
rm -f *_test.json
rm -f presti_scores.csv

# Sauvegarder avant nettoyage complet
cp company_news.json company_news_backup.json
cp jobs_data.json jobs_data_backup.json
```

## ğŸ“‹ Checklist Ajout Entreprise

- [ ] Ajouter Ã  `database/jobs_data.json`
- [ ] GÃ©nÃ©rer/Scraper actualitÃ©s vers `database/company_news.json`
- [ ] Copier vers `public/news_data.json`
- [ ] Ajouter Ã  `public/data.json` si nÃ©cessaire
- [ ] VÃ©rifier affichage dans l'interface web
- [ ] Documenter dans CHANGEMENTS_EFFECTUES.md

## ğŸ†˜ DÃ©pannage

### Les actualitÃ©s n'apparaissent pas

```bash
# VÃ©rifier que news_data.json existe
ls -lh public/news_data.json

# VÃ©rifier le contenu
python3 -c "
import json
with open('public/news_data.json', 'r') as f:
    data = json.load(f)
    print(f'{len(data)} entreprises')
"

# Recopier depuis database
cp database/company_news.json public/news_data.json
```

### Entreprise manquante

```bash
# VÃ©rifier dans tous les fichiers
python3 -c "
import json

company = 'Pottery Barn'  # Nom Ã  chercher

print(f'Recherche de: {company}')

# jobs_data.json
with open('database/jobs_data.json', 'r') as f:
    jobs = json.load(f)
    found = any(c.get('company', {}).get('name') == company for c in jobs['companies'])
    print(f'  jobs_data.json: {\"âœ…\" if found else \"âŒ\"}')

# company_news.json
with open('database/company_news.json', 'r') as f:
    news = json.load(f)
    found = company in news
    print(f'  company_news.json: {\"âœ…\" if found else \"âŒ\"}')

# public/data.json
with open('public/data.json', 'r') as f:
    data = json.load(f)
    found = company.lower() in data.get('companies', {})
    print(f'  public/data.json: {\"âœ…\" if found else \"âŒ\"}')

# public/news_data.json
with open('public/news_data.json', 'r') as f:
    news_front = json.load(f)
    found = company in news_front
    print(f'  public/news_data.json: {\"âœ…\" if found else \"âŒ\"}')
"
```

## ğŸš€ Scripts Utiles ConservÃ©s

- `database/generate_new_companies_data.py` - GÃ©nÃ©rer donnÃ©es manuelles
- `database/scrape_company_news_async.py` - Scraper avec OpenAI
- `database/update_news.sh` - Workflow complet actualitÃ©s

## ğŸ“š Documentation

- `NOUVELLES_ENTREPRISES.md` - Documentation ajout 8 entreprises
- `NOUVELLES_ENTREPRISES_RESUME.md` - RÃ©sumÃ© exÃ©cutif
- `README_NEWS.md` - Documentation systÃ¨me actualitÃ©s
- `CHANGEMENTS_EFFECTUES.md` - Historique des modifications


